# Zero-Shot Learning: LabelEase

## 프로젝트 개요

ZSL-LabelEase는 제로샷(Zero-Shot) 기반 딥러닝 모델을 활용하여 이미지 데이터의 자동 라벨링(탐지 및 분할) 성능을 검증하고, 실제 라벨링 업무에의 적용 가능성을 실험하는 프로젝트입니다.

이 프로젝트는 세종대학교 `2025-1 AI로봇융합심화PBL 농업모듈` 대학원 강의 과제로 수행되었습니다.


## 배경 및 목적

딥러닝 모델의 성능을 높이기 위해서는 대량의 정밀한 라벨링 데이터가 필요합니다. 특히 classification → detection → segmentation으로 task가 복잡해질수록 라벨링에 필요한 시간과 노력이 기하급수적으로 증가합니다.

이러한 문제를 해결하기 위해 auto labeling 기능을 제공하는 다양한 도구들이 등장하고 있습니다.


## 실험 목표

- 제로샷 모델(Grounded SAM 2)을 활용해 기존에 학습하지 않은 객체(예: "참외")에 대한 탐지 및 분할 성능을 실험적으로 검증합니다.
- 사람이 직접 라벨링한 결과와 제로샷 모델이 자동으로 라벨링한 결과를 비교하여 annotation 보조 도구로서의 실용성을 평가합니다.


## 데이터

- 직접 수집한 "참외" 이미지 데이터셋 사용
- 기존 대형 모델이 학습하지 않은 특수 작물(참외)에 대해 제로샷 모델이 어느 정도까지 탐지/분할이 가능한지 확인


## 평가 방법

- **정량적 평가:**  IoU 등 지표로 수작업 라벨과 모델 라벨의 정확도 비교
- **정성적 평가:**  실제 결과 이미지를 직접 확인하며 모델의 한계와 가능성 해석


## 기대 효과

- 제로샷 모델을 활용한 annotation 보조 가능성 검증
- 데이터 구축 비용 및 시간 절감 효과 분석


## 환경 세팅 및 실행 방법

> **아래 내용은 추후 작성 예정입니다.**
> - Python 환경 및 패키지 설치 방법
> - 모델 체크포인트 다운로드 방법
> - 실험 코드 실행 방법
> - 결과 확인 및 평가 방법


## 참고

- Zero-Shot 모델: [Grounded SAM 2 (GitHub)](https://github.com/IDEA-Research/Grounded-SAM-2)
- 본 프로젝트는 연구 및 실험 목적입니다.


## Contact
E-mail: dhlee@sju.ac.kr
